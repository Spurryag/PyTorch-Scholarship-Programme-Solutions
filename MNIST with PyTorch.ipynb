{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch import optim\n",
    "\n",
    "# Define a transform to normalize the data - Transform the images for network fitting\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                              ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2951, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB : it's more convenient to build the model with a log-softmax output using nn.LogSoftmax or F.log_softmax. Then you can get the actual probabilites by taking the exponential torch.exp(output). With a log-softmax output, you want to use the negative log likelihood loss, nn.NLLLoss.\n",
    "\n",
    "Exercise: Build a model that returns the log-softmax as the output and calculate the loss using the negative log likelihood loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Current model structure\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.8520258679064607\n",
      "Training loss: 0.8027726343826953\n",
      "Training loss: 0.5085920138653915\n",
      "Training loss: 0.41838121835166203\n",
      "Training loss: 0.3768586476029618\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # TODO: Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def test_network(net, trainloader):\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    # Create Variables for the inputs and targets\n",
    "    inputs = Variable(images)\n",
    "    targets = Variable(images)\n",
    "\n",
    "    # Clear the gradients from all Variables\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass, then backward pass, then update weights\n",
    "    output = net.forward(inputs)\n",
    "    loss = criterion(output, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def view_recon(img, recon):\n",
    "    ''' Function for displaying an image (as a PyTorch Tensor) and its \n",
    "        reconstruction also a PyTorch Tensor \n",
    "    '''\n",
    "    \n",
    "    fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True)\n",
    "    axes[0].imshow(img.numpy().squeeze())\n",
    "    axes[1].imshow(recon.data.numpy().squeeze())\n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "        ax.set_adjustable('box-forced')\n",
    "        \n",
    "def view_classify(img, ps):\n",
    "    ''' Function for viewing an image and it's predicted classes.\n",
    "    '''\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,7), ncols=2)\n",
    "    ax1.imshow(img.numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    ax2.set_yticklabels(np.arange(10).astype(int), size='large');\n",
    "    ax2.set_title('Digit Probability')\n",
    "    ax2.set_xlim(0, 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "view_classify(img.view(1, 28, 28), ps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
